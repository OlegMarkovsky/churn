{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score,train_test_split,StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,classification_report,f1_score,average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Загрузка данных и препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 232)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('orange_small_churn_train_data.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>...</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "      <th>Var230</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3052.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>vr93T2a</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>xwM2aC7IdeMC0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1813.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6hQ9lNX</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELof</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>catzS2D</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>ZI9m</td>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1533.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>e4lqvY0</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>686.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>MAz3HNj</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WqMG</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Var1  Var2  Var3  Var4  Var5    Var6  Var7  Var8  Var9   ...    \\\n",
       "0   0   NaN   NaN   NaN   NaN   NaN  3052.0   NaN   NaN   NaN   ...     \n",
       "1   1   NaN   NaN   NaN   NaN   NaN  1813.0   7.0   NaN   NaN   ...     \n",
       "2   2   NaN   NaN   NaN   NaN   NaN  1953.0   7.0   NaN   NaN   ...     \n",
       "3   3   NaN   NaN   NaN   NaN   NaN  1533.0   7.0   NaN   NaN   ...     \n",
       "4   4   NaN   NaN   NaN   NaN   NaN   686.0   7.0   NaN   NaN   ...     \n",
       "\n",
       "    Var222      Var223  Var224  Var225  Var226   Var227         Var228  \\\n",
       "0  vr93T2a  LM8l689qOp     NaN     NaN    fKCe  02N6s8f  xwM2aC7IdeMC0   \n",
       "1  6hQ9lNX  LM8l689qOp     NaN    ELof    xb3V     RAYp        55YFVY9   \n",
       "2  catzS2D  LM8l689qOp     NaN     NaN    FSa2     ZI9m  ib5G6X1eUxUn6   \n",
       "3  e4lqvY0  LM8l689qOp     NaN     NaN    xb3V     RAYp  F2FyR07IdsN7I   \n",
       "4  MAz3HNj  LM8l689qOp     NaN     NaN    WqMG     RAYp  F2FyR07IdsN7I   \n",
       "\n",
       "   Var229  Var230  labels  \n",
       "0     NaN     NaN      -1  \n",
       "1    mj86     NaN      -1  \n",
       "2    mj86     NaN      -1  \n",
       "3     NaN     NaN       1  \n",
       "4     NaN     NaN      -1  \n",
       "\n",
       "[5 rows x 232 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля оттока 0.0744\n",
      "Доля не оттока 0.9256\n"
     ]
    }
   ],
   "source": [
    "print 'Доля оттока',(sum([1. for l in data['labels'] if l == 1])/len(data))\n",
    "print 'Доля не оттока',(-sum([-1. for l in data['labels'] if l == -1])/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop('ID',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data=data.iloc[:,:230]\n",
    "y_data=data.iloc[:,230:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 231)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataT=pd.read_csv('orange_small_churn_test_data.csv')\n",
    "dataT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_dataT=dataT.drop('ID',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproceccing(X1,X2,number_features):\n",
    "    #сливаем вместе чтобы провести единообразный препроцессинг и кодирование категорий\n",
    "    X=pd.concat([X_data,X_dataT])\n",
    "    print X.shape\n",
    "    #Отбросим колонки где данных вообще нет\n",
    "    zero=list()\n",
    "    s=X.describe()\n",
    "    for var in s.columns:\n",
    "        if s[var]['count']==0:zero.append(var)\n",
    "    print zero\n",
    "    print 'Колонки ,которые мы отбросили', len(zero)\n",
    "    real_columns=X.columns.drop(zero)\n",
    "    X=X[real_columns]\n",
    "    print X.shape\n",
    "    #Из 230 колонок выбросли уже 18 где нет данных(из них 16 вещ. и 2 кат.).190(последняя вещ.)-16=174\n",
    "    #разделим на вещ. и категориальные и заполним вещ.пропуски средними,а пропуски категории \"NA\"\n",
    "    num_data=X.iloc[:,:174]\n",
    "    cat_data=X.iloc[:,174:]\n",
    "    num_data_mean=num_data.fillna(num_data.describe().loc['mean'])\n",
    "    cat_data=cat_data.fillna('NA')\n",
    "    print num_data.shape\n",
    "    print cat_data.shape\n",
    "    print y_data.shape\n",
    "    #Мы видели что есть кат признаки с кол-вом категорий более 10000.Возможно это фамилии или персональные данные,\n",
    "    #которые сейчас нам будут только мешать.Проверим есть ли различия по кол-ву категорий в признаке в обучающей и \n",
    "    #тестовой выборке\n",
    "    k=0\n",
    "    for var in cat_data.columns:\n",
    "        for name in list(cat_data.iloc[40000:,:][var].value_counts().index):\n",
    "            if name not in list(cat_data.iloc[:40000,:][var].value_counts().index): k+=1\n",
    "        print var,k\n",
    "        k=0\n",
    "    #Ясно что эти признаки надо убрать, будут только шуметь.Оставим только только признаки с числом категорий меньше\n",
    "    #number_features\n",
    "    k=0\n",
    "    new=list()\n",
    "    for var in cat_data.columns:\n",
    "        if len(cat_data[var].value_counts())<number_features : \n",
    "            k+=1\n",
    "            print 'X_train',var,len(cat_data.iloc[:40000,:][var].value_counts()),'   X_test',var,len(cat_data.iloc[40000:,:][var].value_counts())\n",
    "            new.append(var)\n",
    "    print new\n",
    "    print 'Признаки которые мы оставили',k\n",
    "    cat=cat_data[new]\n",
    "    #Кодируем их\n",
    "    cat_code = cat.apply(LabelEncoder().fit_transform)\n",
    "    cat_code = OneHotEncoder(sparse=False).fit_transform(cat_code)\n",
    "    print cat_code.shape\n",
    "    #Разделяем выборки заново\n",
    "    cat_codeL=cat_code[:40000,:]\n",
    "    cat_codeT=cat_code[40000:,:]\n",
    "    num_data_meanL=num_data_mean.iloc[:40000,:]\n",
    "    num_data_meanT=num_data_mean.iloc[40000:,:]\n",
    "    #Масштабируем признаки\n",
    "    num_data_meanL=StandardScaler().fit_transform(num_data_meanL)\n",
    "    num_data_meanT=StandardScaler().fit_transform(num_data_meanT)\n",
    "    #Собираем признаки вместе\n",
    "    X_selectL=np.hstack( (num_data_meanL,cat_codeL))# обучение\n",
    "    X_selectT=np.hstack( (num_data_meanT,cat_codeT))# тестовая без меток\n",
    "    print X_selectL.shape\n",
    "    \n",
    "    return  X_selectL,X_selectT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 230)\n",
      "['Var8', 'Var15', 'Var20', 'Var31', 'Var32', 'Var39', 'Var42', 'Var48', 'Var52', 'Var55', 'Var79', 'Var141', 'Var167', 'Var169', 'Var175', 'Var185', 'Var209', 'Var230']\n",
      "Колонки ,которые мы отбросили 18\n",
      "(50000, 212)\n",
      "(50000, 174)\n",
      "(50000, 38)\n",
      "(40000, 1)\n",
      "X_train Var191 2    X_test Var191 2\n",
      "X_train Var192 355    X_test Var192 280\n",
      "X_train Var193 50    X_test Var193 41\n",
      "X_train Var194 4    X_test Var194 4\n",
      "X_train Var195 23    X_test Var195 17\n",
      "X_train Var196 4    X_test Var196 3\n",
      "X_train Var197 221    X_test Var197 184\n",
      "X_train Var201 3    X_test Var201 2\n",
      "X_train Var203 6    X_test Var203 5\n",
      "X_train Var204 100    X_test Var204 100\n",
      "X_train Var205 4    X_test Var205 4\n",
      "X_train Var206 22    X_test Var206 22\n",
      "X_train Var207 14    X_test Var207 11\n",
      "X_train Var208 3    X_test Var208 3\n",
      "X_train Var210 6    X_test Var210 6\n",
      "X_train Var211 2    X_test Var211 2\n",
      "X_train Var212 78    X_test Var212 67\n",
      "X_train Var213 2    X_test Var213 2\n",
      "X_train Var215 2    X_test Var215 2\n",
      "X_train Var218 3    X_test Var218 3\n",
      "X_train Var219 23    X_test Var219 16\n",
      "X_train Var221 7    X_test Var221 7\n",
      "X_train Var223 5    X_test Var223 5\n",
      "X_train Var224 2    X_test Var224 2\n",
      "X_train Var225 4    X_test Var225 4\n",
      "X_train Var226 23    X_test Var226 23\n",
      "X_train Var227 7    X_test Var227 7\n",
      "X_train Var228 30    X_test Var228 26\n",
      "X_train Var229 5    X_test Var229 5\n",
      "['Var191', 'Var192', 'Var193', 'Var194', 'Var195', 'Var196', 'Var197', 'Var201', 'Var203', 'Var204', 'Var205', 'Var206', 'Var207', 'Var208', 'Var210', 'Var211', 'Var212', 'Var213', 'Var215', 'Var218', 'Var219', 'Var221', 'Var223', 'Var224', 'Var225', 'Var226', 'Var227', 'Var228', 'Var229']\n",
      "Признаки которые мы оставили 29\n",
      "(50000L, 1026L)\n",
      "(40000L, 1200L)\n"
     ]
    }
   ],
   "source": [
    "X_selectL, X_selectT = preproceccing(X_data,X_dataT,number_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000L, 1200L) (12000L, 1200L)\n",
      "(28000L,) (12000L,)\n"
     ]
    }
   ],
   "source": [
    "X, X_holdout, y, y_holdout = train_test_split(X_selectL, np.array(y_data).reshape(40000,), \n",
    "                                              test_size=0.3, random_state=0, stratify=y_data)\n",
    "print X.shape,X_holdout.shape\n",
    "print y.shape,y_holdout.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Обучение.\n",
    "Я выбрал LogisticRegression и GradientBoostingClassifier,бустинг после балансировки дал более высокие уровни метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Выбираем тип разбиения для кросс-валидации\n",
    "#Делаем кроссвалидацию по F-мере,ROC-AUC,PRC\n",
    "cv=StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1                0.013252868091\n",
      "average_precision 0.193256497567\n",
      "roc_auc           0.72973463646\n"
     ]
    }
   ],
   "source": [
    "clf=GradientBoostingClassifier(n_estimators=50,random_state=1)\n",
    "CV=cross_val_score(clf,X,y,scoring = 'f1',cv=cv)\n",
    "CV1=cross_val_score(clf,X,y,scoring = 'average_precision',cv=cv)\n",
    "CV2=cross_val_score(clf,X,y,scoring = 'roc_auc',cv=cv)\n",
    "print 'f1               ',CV.mean()\n",
    "print 'average_precision',CV1.mean()\n",
    "print 'roc_auc          ',CV2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51834L,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#F1-мера явно низкая\n",
    "#Сбалансируем классы досэмплитровав объекты минорного класса\n",
    "np.random.seed(1)\n",
    "indices_to_add = np.random.randint(np.sum(y==1),size=(np.sum(y==-1)-np.sum(y==1)))\n",
    "X_a =X[y == 1,:][indices_to_add,:]\n",
    "X_add=np.vstack( (X,X_a) )\n",
    "ones= np.ones((np.sum(y==-1)-np.sum(y==1)))\n",
    "y_add=np.hstack((y, ones))\n",
    "y_add.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1                0.697924418976\n",
      "average_precision 0.751002701911\n",
      "roc_auc           0.766427675931\n"
     ]
    }
   ],
   "source": [
    "clf=GradientBoostingClassifier(n_estimators=50,random_state=1)\n",
    "CV=cross_val_score(clf,X_add,y_add,scoring = 'f1',cv=cv)\n",
    "CV1=cross_val_score(clf,X_add,y_add,scoring = 'average_precision',cv=cv)\n",
    "CV2=cross_val_score(clf,X_add,y_add,scoring = 'roc_auc',cv=cv)\n",
    "print 'f1               ',CV.mean()\n",
    "print 'average_precision',CV1.mean()\n",
    "print 'roc_auc          ',CV2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=1,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#уже все получше.Пробуем обучить и проверить на отложенной выборке\n",
    "gb=GradientBoostingClassifier(n_estimators=50,random_state=1)\n",
    "gb.fit(X_add, y_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_predictions=gb.predict_proba(X_holdout)\n",
    "gb_predictions1=gb.predict(X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.96      0.68      0.80     11107\n",
      "          1       0.15      0.69      0.24       893\n",
      "\n",
      "avg / total       0.90      0.68      0.75     12000\n",
      "\n",
      "f1                0.242686039662\n",
      "average_precision 0.431054397963\n",
      "roc_auc           0.745956541434\n"
     ]
    }
   ],
   "source": [
    "auc=roc_auc_score(y_holdout,gb_predictions[:,1]  ) \n",
    "print(classification_report(y_holdout,gb_predictions1 ) )\n",
    "f1=f1_score(y_holdout,gb_predictions1)\n",
    "avr=average_precision_score(y_holdout,gb_predictions1)\n",
    "print 'f1               ',f1\n",
    "print 'average_precision',avr\n",
    "print 'roc_auc          ',auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем подбирать параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.766427675931\n",
      "100 0.792403682581\n",
      "150 0.810539567256\n"
     ]
    }
   ],
   "source": [
    "number=[50, 100, 150]\n",
    "for n in number:\n",
    "    clf = GradientBoostingClassifier(n_estimators=n,random_state=1)\n",
    "    auc=cross_val_score(clf, X_add, y_add, cv=cv, scoring='roc_auc')\n",
    "    print n, auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.792403682581\n",
      "5 0.791600375571\n",
      "10 0.791618756794\n"
     ]
    }
   ],
   "source": [
    "number=[1, 5, 10]\n",
    "for n in number:\n",
    "    clf = GradientBoostingClassifier(min_samples_leaf=n,random_state=1)\n",
    "    auc=cross_val_score(clf, X_add, y_add, cv=cv, scoring='roc_auc')\n",
    "    print n, auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.792403682581\n",
      "5 0.863068307898\n",
      "7 0.928121992883\n"
     ]
    }
   ],
   "source": [
    "number=[3, 5, 7]\n",
    "for n in number:\n",
    "    clf = GradientBoostingClassifier(max_depth=n,random_state=1)\n",
    "    auc=cross_val_score(clf, X_add, y_add, cv=cv, scoring='roc_auc')\n",
    "    print n, auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#есть подозрение что мы переобучились"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=5,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=150, presort='auto', random_state=1,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb=GradientBoostingClassifier(n_estimators=100,min_samples_leaf=1,max_depth=1,random_state=1)\n",
    "gb.fit(X_add, y_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_predictions=gb.predict_proba(X_holdout)\n",
    "gb_predictions1=gb.predict(X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.96      0.76      0.85     11107\n",
      "          1       0.16      0.56      0.25       893\n",
      "\n",
      "avg / total       0.90      0.75      0.80     12000\n",
      "\n",
      "f1                0.248069738481\n",
      "average_precision 0.375050285975\n",
      "roc_auc           0.726938037623\n"
     ]
    }
   ],
   "source": [
    "auc=roc_auc_score(y_holdout,gb_predictions[:,1]  ) \n",
    "print(classification_report(y_holdout,gb_predictions1 ) )\n",
    "f1=f1_score(y_holdout,gb_predictions1)\n",
    "avr=average_precision_score(y_holdout,gb_predictions1)\n",
    "print 'f1               ',f1\n",
    "print 'average_precision',avr\n",
    "print 'roc_auc          ',auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_predictions1=gb.predict_proba(X_selectT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rez=pd.DataFrame(data=gb_predictions1[:,1], columns=['result'])\n",
    "rez.to_csv('rez3.csv',index=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#На kaggle загрузил вероятности по классу 1,результат в скриншоте 0.7270 ,что выше бэнчмарка"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
